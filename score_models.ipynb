{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd.read_csv('datasets/test_set.csv')['cpi_pct'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca_bma rmse: 0.0030218\n",
      "pca_lasso_bic rmse: 0.0024414\n",
      "pca_lasso_cv rmse: 0.0024375\n",
      "pca_lasso_cvshuffled rmse: 0.0032184\n",
      "pca_lasso_ebic rmse: 0.0030582\n",
      "pca_ols rmse: 0.0030814\n",
      "pca_ridge_cv rmse: 0.0024442\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "for file_name in os.listdir('predictions/'):\n",
    "    \n",
    "    if file_name[:3] != 'pca':\n",
    "        continue\n",
    "    \n",
    "    y_pred = pd.read_csv(f'predictions/{file_name}', index_col=0).to_numpy()\n",
    "    \n",
    "    name = file_name.rsplit('.', 1)[0]\n",
    "    rmse =  mean_squared_error(y_true, y_pred, squared=False)\n",
    "    print(name, \"rmse:\", round(rmse, 7))\n",
    "    prediction.append({'model': name, 'rmse': rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = ['benchmark1_mean', 'benchmark2_prev', 'benchmark3_rf', \n",
    "           'ols','ridge_cv', 'lasso_cv', 'lasso_cvshuffled',\n",
    "           'lasso_bic', 'lasso_ebic', 'bma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(prediction).set_index('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df['diff to best'] =  score_df.rmse - score_df.rmse.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_df.loc[sorting, :].to_csv('results/1970_2023_model_scores.csv')\n",
    "score_df.sort_values('rmse').to_csv('results/1970_2023_pca_model_scores_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>diff to best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pca_bma</th>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca_lasso_bic</th>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca_lasso_cv</th>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca_lasso_cvshuffled</th>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca_lasso_ebic</th>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca_ols</th>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.000644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca_ridge_cv</th>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          rmse  diff to best\n",
       "model                                       \n",
       "pca_bma               0.003022      0.000584\n",
       "pca_lasso_bic         0.002441      0.000004\n",
       "pca_lasso_cv          0.002438      0.000000\n",
       "pca_lasso_cvshuffled  0.003218      0.000781\n",
       "pca_lasso_ebic        0.003058      0.000621\n",
       "pca_ols               0.003081      0.000644\n",
       "pca_ridge_cv          0.002444      0.000007"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2000-2023 model:\n",
    "\n",
    "- benchmark1_mean rmse: 0.0026948\n",
    "- benchmark2_prev rmse: 0.0034082\n",
    "- bma rmse: 0.002297\n",
    "- lasso_bic rmse: 0.0023243\n",
    "- lasso_ebic rmse: 0.0023711\n",
    "- lasso_cv rmse: 0.0027338\n",
    "- lasso_cvshuffled rmse: 0.0027338\n",
    "- ols rmse: 0.0279417\n",
    "- ridge_cv rmse: 0.0024787"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1970-2023 model:\n",
    "\n",
    "- benchmark1_mean rmse: 0.0032184\n",
    "- benchmark2_prev rmse: 0.0026672\n",
    "- benchmark3_rf rmse: 0.0020702\n",
    "- bma rmse: 0.0020429\n",
    "- lasso_bic rmse: 0.0021015\n",
    "- lasso_cv rmse: 0.0021016\n",
    "- lasso_cvshuffled rmse: 0.0019987\n",
    "- lasso_ebic rmse: 0.0021058\n",
    "- ols rmse: 0.0030478\n",
    "- ridge_cv rmse: 0.0021375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1970-2023 model (PCA):\n",
    "\n",
    "- benchmark1_mean rmse: 0.0026948\n",
    "- benchmark2_prev rmse: 0.0034082\n",
    "- benchmark3_rf rmse: 0.0020702\n",
    "- bma rmse: 0.002297\n",
    "- lasso_bic rmse: 0.0023243\n",
    "- lasso_ebic rmse: 0.0023711\n",
    "- lasso_cv rmse: 0.0027338\n",
    "- lasso_cvshuffled rmse: 0.0027338\n",
    "- ols rmse: 0.0279417\n",
    "- ridge_cv rmse: 0.0024787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bma_coefs\n",
      "lasso_bic_coefs\n",
      "lasso_cvshuffled_coefs\n",
      "lasso_cv_coefs\n",
      "lasso_ebic_coefs\n",
      "ols_coefs\n",
      "ridge_cv_coefs\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "\n",
    "\n",
    "for file_name in os.listdir('models/coefs/'):\n",
    "    \n",
    "    coefs = pd.read_csv(f'models/coefs/{file_name}', index_col=0)\n",
    "    \n",
    "    if file_name == \"bma_coefs.csv\":  \n",
    "        coefs = coefs.rename({'intercept': 'Intercept'})\n",
    "     \n",
    "    name = file_name.rsplit('.', 1)[0]\n",
    "    \n",
    "    if name[-5:] != 'coefs':\n",
    "        continue\n",
    "\n",
    "    coefs.columns = [name[:-6]]\n",
    "    \n",
    "\n",
    "    print(name)\n",
    "    df_list.append(coefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list, axis=1).replace(-0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results/all_model_coefs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = df.abs().sort_values('bma', ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[sorted_idx, :].to_csv('results/all_model_coefs_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Uni py312",
   "language": "python",
   "name": "uni"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
